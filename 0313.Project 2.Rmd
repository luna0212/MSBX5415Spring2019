---
title: "MSBX 5415: Term Project Proposal 2"
subtitle: "TMDB Box Office Prediction"
author: "David Witzig,Gage Clifton,Kaid Beziou,Luna Liu"
date: "3/13/2019"
#output: word_document
output: pdf_document
---

```{r, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	fig.height = 3,
	fig.width = 4,
	message = FALSE,
	comment = NA)
```
# 1) Data Cleansing

## a) Data overview
```{r}
library(jsonlite); library(stringr); library(plyr); library(data.table)
library(tidyverse); library(xgboost); library(stringi); library(caret)
df <- read.csv("train.csv", header = TRUE)
```
There are 23 variables in this train dataset, including:
- Continuous variables: budget, popularity, runtime and revenue; 
- Long text: original_title, overiview, tangline, title and keywords;
- JSON type text: belongs_to_collection, genres, production_companies, production_countries, spoken_languages, keywords, cast, crew;
- Categorical name: X...id, imdb_id, status,
- Hyperlink text: homepage, poster_path
- Date: release_date
```{r}
df = df[,-c(9,11,12,18,20,21,22)]
```
* Omit dictionary variables and long text for now.


## b) Missing value
```{r}
df[df== ""] <- NA
na.cols <- which(colSums(is.na(df)) > 0)
na.cols <- sort(colSums(sapply(df[na.cols], is.na)), decreasing = TRUE)
na.cols
```
* There are 6 variables have NA value.

```{r}
df = df %>% 
  mutate(
    belongs_to_collection_flag = ifelse(is.na(belongs_to_collection) == TRUE,1,0),
    hasHomePage = ifelse(is.na(homepage) == TRUE, 1, 0))

df = subset(df, select=-c(belongs_to_collection,homepage))
df$runtime[is.na(df$runtime)] <- 0
```
* Another possibly useful feature is the fact of belonging to a collection. So we convert the non empty belongs_to_collection to flag 1, 
empty belongs_to_collection to flag 0.
Similar remarks apply to the homepage.
* Fill the NA runtime variables of 0.

## c) Date formating
```{r}
date.format <- as.Date(df$release_date, format="%m/%d/%Y")
year.fun = function(x){
  if(is.na(x)){
    return(paste0("2000"))
  }else if(x < 10){
    return(paste0("200",x))
  }else if(x >=10 & x <= 18){
    return(paste0("20", x))
  }else{
    return(paste0("19",x))
  }
}

df = df %>% 
  mutate(year = year(date.format),
         year = sapply(year, year.fun) %>% as.numeric(),
         month = month(date.format),
         weekday = as.numeric(as.factor(weekdays(date.format))))
```
* The release_date variable is not in datetime format. Also, the year variable is two-digit format. When tranform the release_date into datatime format, two-digit format causes problems. So we used some extra functions to clean it up.

## d) Number cleaning
```{r}
for (i in 1:nrow(df)) {
  if(df[i,"budget"] > 1000 & df[i,"revenue"] < 100){
    df[i,"revenue"] = df[i,"revenue"] * 10^6
  }
}
```
* There are some outliers for revenue. 

## e) Near zero variance
```{r}
nzv = nearZeroVar(df)
df = df[, -nzv]
```
* Original_language and Status are near zero variables. Becuase most of the original_language are English, and most of the status are released.

## f) Deal with JSON format
```{r}
str_converter <- function(x, slasher = FALSE){
  string_split <- str_split(x, '"', simplify = TRUE)
  index1 <- (1:length(string_split)) %% 2 != 0
  index2 <- (1:length(string_split)) %% 2 == 0
  string_split[index1] <- gsub("'", "\"", string_split[index1])
  string_split[index2] <- "0"
  string_all <- paste(string_split, sep = "\"", collapse = "")
  string_all <- gsub("None", '"None"', string_all)
  if (slasher == TRUE){                     
    string_all <- gsub("\\\\\\D", "", string_all)}
  string_all
}

for(i in 1:nrow(df)) {
  row <- df[i,]
  if (is.na(row$production_countries) == FALSE){
      mydf <- fromJSON(str_converter(row$production_countries))
      for (n in mydf$iso_3166_1){
        df[i,n] <- 1}}
}

df = subset(df, select=-c(production_countries))
```
* Some variavles are in JSON format. We extarct the content and convert it to dummy variables.
This code is the example of converting production country. Similar remarks apply to the genres and spoken languages.

# 2) Important Feature Analysis
```{r}
par(mfrow=c(1,3),cex = 0.65)
plot(df$budget,df$revenue,pch = 21, lwd = 0.4, 
     bg = "hotpink1",xlab = "Budget", ylab ="Revenue")
abline(lm(revenue~budget,data=df),col="blue",lwd=1.5)

plot(df$popularity,df$revenue,pch = 21, lwd = 0.4, 
     bg = "hotpink1",xlab = "Popularity", ylab = "Revenue")
abline(lm(revenue~popularity,data=df),col="blue",lwd=1.5)

plot(df$runtime,df$revenue,pch = 21, lwd = 0.4, 
     bg = "hotpink1",xlab = "Runtime", ylab = "Revenue")
abline(lm(revenue~runtime,data=df),col="blue",lwd=1.5)
```

* From these plots it is clear that Revenue and Budget have a moderate positive linear relationship, Revenue and Popularity appear to be weakly positively correlated (a transformation may be needed), and lastly revenue and runtime do not appear to be strongly linearly related. Although these relationships aren't perfect, we wanted to see their combined effects from a regression model. 


# 3) Modeling
```{r}
model1 = lm(revenue~budget+popularity+runtime,data=df)
```
* Each of the continuous variables were statistically significant at the 5% level, and combined they explained 0.614 (Adj R-squared) of the linear variation of revenue. These are great results for our first model,  leading us to believe that revenue is statistically predictable. As such, we created another linear regression model for all of the cleaned variables (except titles,IDs and date). 

```{r}
df <- read.csv("0311_cleaned_train.csv", header = TRUE)
model2 = lm(revenue~.-title-original_title-imdb_id-X...id-release_date-month-weekday+
              factor(month)+factor(weekday),data=df)
```
* This regression explains 0.656 (Adj R-Squared) of the linear variation in revenue. Continuous variables budget, popularity, runtime were statistically significant at the 5% level. Some other variables such as certain spoken language and certain weekday were statistically significant too.
However, we noticed that many of the variables are not statistically significant, leading us to believe that we may have over fit the model. Going forward, we are going to look for ways to reduce the number of variables, as well as, see how the models perform on the test data.


# 4) Future Steps
## a) Model improvment
In order to improve upon the initial cleanup we conducted on the TMDB Box Office Description for the final analysis we first need to come up with creative solutions to include more of the variables in our analysis. Many of the variables we did not perform initial clean up of or include in our preliminary regressions were json formatted lists of strings. These will require a substantial amount of modification if we intend to include them as variables in our analysis. An idea we came up with to deal with the json variables is to parse them out and categorize the lists into factorable variables. For example, for "Cast" we could download a list of the 1000 most popular actors and actresses and match each to each respective movie they play a role in. We could then determine whether or not each movie had an "A-list" celebrity actor/actress in it or not and thus perform a regression on whether or not these A-list actors/actresses had an effect on overall revenue. Additionally, we could take a similar approach to the production companies involved with production of a given movie to determine if the largest, most prominent production companies tended to produce high grossing movies.

Additionally, we need to conduct some imputation of the movies that had no listed "movie budget" as budget will likely be highly indicative of the revenue produced as well. Many of the movies had no listed budget, which defaulted in our dataset to a value of zero. One proposed solution we have would be to create a profitability to budget ratio in order to scale both of the values and then to impute the missing budget variables (for movies which budget was missing) and set those movies equal to the average profitability ratio level, thus, imputing the budget associated.

One other idea we came up with as an interesting way to include the "keywords" variable was to sort the keywords column in such a way to test whether or not there were common "cultural themes" associated with different years and test whether or not specific themed movies tended to produce higher levels of revenue. If so, we could test whether or not the theme described by the keywords have an effect on revenue and if so, was there an interaction with the year.

One final idea we had for improvement of our initial model was to create a comparative list of all major holidays throughout the country (and world if applicable) and test to see if there is any relationship between revenue and movies that were released on a major holiday.


## b) Variable cleanup improvment 
To create the best model for our analysis and process the data further our team needs to find solutions to many problems in the original dataset. Many variables within our dataset need to be scaled and modified to be useful.

The first example is related to the movie name titles denoted in a foreign language. Most non-English titles are not processed by R to read in the names correctly and instead produce odd characters instead of using correct foreign character set. We plan on either researching possible package solutions that might allow us R to process these characters or omitting foreign films from our analysis since the English movie dataset is large enough for us to analyze. We prefer the former due to our team seeing value in analyzing movie titles for keywords but are not sure about the possibility yet.

Another avenue of analysis relates to extracting popular actors' names from the crew variable to examine the relationship between high profile actors and revenue generation. Since big-budget actors are sometimes viewed as whether a movie will be successful or not, our team wants to analyze whether having a "big name" acting in a movie will result in higher revenues. The data in this variable is stored in .json files and our team needs to develop a method to merge the selected .json names with a .csv list of the most popular actors. We will have to quantitatively select a cut-off for what qualifies a person as a high-profile actor based on cost and other factors.

One other variable that is crucial to our team's project is popularity. The popularity variable indicates the audience and critic aggregate score of the movie, but it is not scaled correctly in the original data. Some titles are on a 5-point scale with other titles being on as high at 233.67. This is a problem as popularity is expected to a significant indicator in deriving the revenue based on budget, but without accurate scale it is difficult to use in our analysis. The majority of the titles are based on a 5-point scale, and so we plan to imputing an average on all titles that have a popularity variable that is.



